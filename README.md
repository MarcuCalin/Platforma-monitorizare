# ğŸ§  Platforma de Monitorizare a StÄƒrii unui Sistem

## ğŸ¯ Scopul Proiectului
Acest proiect demonstreazÄƒ o soluÈ›ie completÄƒ DevOps care integreazÄƒ:

- ğŸ” Monitorizarea sistemului prin scripturi automate;
- ğŸ’¾ Backup periodic al logurilor;
- ğŸ³ Containerizare cu **Docker** È™i orchestrare cu **Docker Compose**;
- â˜¸ï¸ Rulare Ã®n **Kubernetes** folosind **Minikube**;
- âš™ï¸ Automatizare completÄƒ cu **Ansible**.

---

## ğŸ—ï¸ Arhitectura Proiectului

### ğŸ“˜ Structura GeneralÄƒ
```
ğŸ“‚ proiect-monitoring
â”œâ”€â”€ /scripts
â”‚ â”œâ”€â”€ system_monitor.sh # Script Shell care monitorizeazÄƒ sistemul È™i genereazÄƒ system-state.log
â”‚ â””â”€â”€ backup_script.py # Script Python care creeazÄƒ backup pentru loguri
â”‚
â”œâ”€â”€ /docker
â”‚ â”œâ”€â”€ Dockerfile.monitoring # Imagine Docker pentru scriptul de monitorizare
â”‚ â”œâ”€â”€ Dockerfile.backup # Imagine Docker pentru scriptul de backup
â”‚ â”œâ”€â”€ docker-compose.yml # DefineÈ™te È™i porneÈ™te containerele monitor È™i backup
â”‚
â”œâ”€â”€ /kubernetes
â”‚ â”œâ”€â”€ namespace.yaml # CreeazÄƒ namespace-ul "monitoring"
â”‚ â”œâ”€â”€ deployment.yaml # Deployment cu 2 replici È™i 3 containere (monitor, backup, nginx)
â”‚ â”œâ”€â”€ hpa.yaml # Configurare HPA (Horizontal Pod Autoscaler)
â”‚
â””â”€â”€ /ansible
â”œâ”€â”€ install_docker.yml # InstaleazÄƒ Docker pe maÈ™ina nouÄƒ
â””â”€â”€ run_compose.yml # RuleazÄƒ docker-compose.yml pe maÈ™ina nouÄƒ
```
## Directorul `/scripts`

Acest director conÈ›ine scripturile folosite pentru colectarea informaÈ›iilor despre sistem È™i realizarea backup-ului automat.

 **`monitoring.sh'**

MonitorizeazÄƒ Ã®n timp real sistemul (CPU, memorie, disk, procese active, hostname etc.);

Scrie rezultatele Ã®n fiÈ™ierul system-state.log;

Este rulat periodic printr-un container dedicat.

Exemplu rulare manualÄƒ:

bash scripts/monitoring.sh
 
 **`backup.py '**

VerificÄƒ existenÈ›a fiÈ™ierului system-state.log;

CreeazÄƒ un backup Ã®ntr-un fiÈ™ier cu timestamp;

Este declanÈ™at automat din containerul backup.

Rulare manualÄƒ:

python3 scripts/backup.py

- **`system-state.log`**  
  FiÈ™ierul generat de `monitoring.sh` care conÈ›ine informaÈ›ii detaliate despre starea sistemului.

**Rol general:**  
Directorul `scripts` centralizeazÄƒ logica aplicaÈ›iei, oferind fiÈ™iere independente care pot fi testate local sau containerizate ulterior.

---

## Directorul `/docker`

Directorul **`docker`** conÈ›ine fiÈ™ierele necesare pentru containerizarea scripturilor È™i orchestrarea lor cu Docker Compose.

- **`Dockerfile.monitoring`**  
  DefineÈ™te imaginea Docker pentru scriptul de monitorizare Bash:
  - PorneÈ™te de la Debian Bookworm.
  - InstaleazÄƒ pachetele necesare (`sysstat`, `procps`) pentru colectarea informaÈ›iilor de sistem.
  - CopiazÄƒ scriptul `monitoring.sh` din `/scripts` Ã®n container È™i Ã®l face executabil.
  - CMD-ul porneÈ™te automat scriptul la rularea containerului.

- **`Dockerfile.backup`**  
  DefineÈ™te imaginea Docker pentru scriptul Python de backup:
  - PorneÈ™te de la `python:3.11-slim`.
  - CopiazÄƒ `backup.py` din `/scripts` Ã®n container.
  - CMD-ul porneÈ™te scriptul automat la rularea containerului.

- **`docker-compose.yml`**  
  Orchestrarea ambelor containere, configurÃ¢nd:
  - Serviciile `monitor` È™i `backup`.
  - Volume pentru persistarea fiÈ™ierului `system-state.log` È™i a backup-urilor.
  - Variabile de mediu pentru intervale È™i directoare.
  - ReÈ›ea implicitÄƒ pentru comunicarea Ã®ntre containere (backup poate accesa fiÈ™ierul generat de monitor).

**LegÄƒtura dintre Dockerfile-uri È™i scripturi:**  
Fiecare Dockerfile porneÈ™te un script din `/scripts` È™i configureazÄƒ mediul necesar pentru ca acesta sÄƒ funcÈ›ioneze independent Ã®n container. Docker Compose conecteazÄƒ containerele Ã®ntre ele prin volume, astfel Ã®ncÃ¢t:
- `monitor` scrie log-ul Ã®ntr-un volum partajat.
- `backup` citeÈ™te log-ul È™i genereazÄƒ backup-uri automat.

- `/ansible`: [Descriere rolurilor playbook-urilor È™i inventory]
- `/jenkins`: [Descrierea rolului acestui director si a subdirectoarelor. Unde sunt folosite fisierele din acest subdirector.]
- `/terraform`: [Descriere rol fiecare fisier Terraform folosit]

##  Setup È™i Rulare

AceastÄƒ secÈ›iune descrie **toÈ›i paÈ™ii necesari** pentru a instala, configura È™i rula proiectul, atÃ¢t local, cÃ¢t È™i remote, folosind Ansible.

---

### ğŸ§° 1. Tool-uri necesare

Ãnainte de a Ã®ncepe, asigurÄƒ-te cÄƒ ai instalate urmÄƒtoarele:

| Tool | Versiune recomandatÄƒ | Scop |
|------|----------------------|------|
| **Docker** | â‰¥ 24.x | Rularea containerelor |
| **Docker Compose** | â‰¥ 2.x | Orchestrarea serviciilor |
| **Ansible** | â‰¥ 2.15.x | Automatizarea instalÄƒrii È™i deploy-ului |
| **Python** | â‰¥ 3.10 | ExecuÈ›ia scriptului de backup |
| **Minikube** | â‰¥ 1.33 | Cluster Kubernetes local |
| **kubectl** | compatibil cu Minikube | InteracÈ›iune cu Kubernetes |
| **OpenSSH** | latest | Conectare la VM remote |
| **VirtualBox** *(opÈ›ional)* | pentru VM-uri locale | Testare Ã®n mediu izolat |

---

### ğŸ–¥ï¸ 2. Configurare localÄƒ

CloneazÄƒ proiectul È™i intrÄƒ Ã®n director:
```bash
git clone https://github.com/MarcuCalin/Platforma-monitorizare/
cd monitoring-platform


cd docker
docker-compose up --build -d
docker ps
Ar trebui sÄƒ vezi douÄƒ containere:

system-monitor

system-backup

VerificÄƒ logurile generate:

bash
Copy code
docker logs system-monitor
docker logs system-backup
VerificÄƒ existenÈ›a backup-urilor:

bash
Copy code
ls scripts/backup/

Pe masina client citim cheia publica a userului curent
cat ~/.ssh/id_rsa.pub

Pe masina remote (masina noua) adaugam un user nou si ii setam cheia de ssh
sudo adduser ansible_user

Adaugam userul ansible in userii cu drept de sudo
sudo usermod -aG sudo ansible_user
groups ansible_user

Adaugam userul de ansible in lista de useri ce nu au nevoie de parola la sudo
cd /etc/sudoers.d/
echo "ansible_user ALL=(ALL) NOPASSWD:ALL" | sudo tee ansible_user-nopasswd
# (ansible este userul pe care il foloseste Ansible sa faca ssh pe masina server)

su - ansible_user

Verificam ca putem face sudo fara parola
sudo ls

Adaugam cheia de ssh a userului ansible in masina remote. Atentie: trebuie sa fiti logati cu userul ansible cand rulati aceste comenzi

mkdir .ssh
touch ~/.ssh/authorized_keys
echo â€œcheie ssh publica de pe masina clientâ€ >> ~/.ssh/authorized_keys
cat ~/.ssh/authorized_keys



Install ssh server pe masina remote
sudo apt update
sudo apt install -y openssh-server
service ssh status

Luam IP-ul masinii remote 
ip addr | grep 192.168

Revenim pe masina client (ubuntu2204) si incercam sa facem ssh cu userul ansible
ssh ansible_user@192.168.x.xxx

Configurare fiÈ™ier inventory Ansible

CreeazÄƒ sau actualizeazÄƒ fiÈ™ierul ansible/inventory.ini:

[monitoring]
app1 ansible_host=192.168.x.xx ansible_user=ansible_user

Instalare Docker pe VM (playbook install_docker.yml)

RulÄƒm urmÄƒtoarea comandÄƒ:

ansible-playbook -i ansible/inventory.ini ansible/playbooks/install_docker.yml

Ce face acest playbook:

ActualizeazÄƒ lista de pachete;

InstaleazÄƒ docker.io;

PorneÈ™te È™i enableazÄƒ serviciul Docker.

Deploy aplicaÈ›ie (playbook deploy_platform.yml)
ansible-playbook -i ansible/inventory.ini ansible/playbooks/deploy_platform.yml

Ce face acest playbook:

CopiazÄƒ fiÈ™ierele docker/ pe maÈ™ina remote;

RuleazÄƒ docker-compose up -d pentru a porni serviciile.

Verificare succes deploy

Pe maÈ™ina remote:

docker ps

Ar trebui sÄƒ aparÄƒ:

CONTAINER ID   IMAGE             STATUS          PORTS
a1b2c3d4e5f6   system-monitor    Up 10 seconds   ...
b2c3d4e5f6g7   system-backup     Up 10 seconds   ...

VerificÄƒ backup-ul:

ls /home/devops/docker/scripts/backup/

VerificÄƒ logurile:

docker logs system-monitor
```
## â˜¸ï¸ Setup È™i rulare Ã®n Kubernetes

AceastÄƒ aplicaÈ›ie poate fi rulatÄƒ Ã®ntr-un cluster Kubernetes (de exemplu Minikube) pentru a demonstra orchestrarea È™i autoscalarea containerelor.

### PaÈ™i de rulare

1. **PorniÈ›i Minikube**:
```bash
ubectl apply -f k8s/namespace.yaml
kubectl get ns
AplicaÈ›i deployment-ul cu 2 replici:

bash
Copy code
kubectl apply -f k8s/deployment.yaml
kubectl get pods -n monitoring
Fiecare pod conÈ›ine 3 containere: monitor, backup È™i nginx.

nginx expune fiÈ™ierul de log generat de containerul monitor.

AplicaÈ›i HPA (Horizontal Pod Autoscaler):

bash
Copy code
kubectl apply -f k8s/hpa.yaml
kubectl get hpa -n monitoring
HPA ajusteazÄƒ numÄƒrul de replici Ã®ntre 2 È™i 10 pe baza utilizÄƒrii CPU È™i memoriei.

VerificaÈ›i logurile È™i starea containerelor:

bash
Copy code
kubectl logs <pod_name> -c monitor -n monitoring
kubectl logs <pod_name> -c backup -n monitoring
kubectl get pods -n monitoring
AccesaÈ›i fiÈ™ierul de log prin Nginx:

DacÄƒ Minikube ruleazÄƒ pe maÈ™ina localÄƒ:

bash
Copy code
minikube service nginx-service -n monitoring
Aceasta va deschide Ã®n browser fiÈ™ierul de log partajat Ã®ntre containere.

ğŸ–¼ï¸ Diagrama arhitecturii Ã®n Kubernetes
sql
Copy code
          +--------------------+
          |      User/Client   |
          +---------+----------+
                    |
                    v
          +--------------------+
          |     Nginx Pod      |  <- Expune logurile
          +---------+----------+
                    |
   +----------------+----------------+
   |                                 |
   v                                 v
+--------+                       +--------+
| Monitor|                       | Backup |
|Container|                       |Container|
+--------+                       +--------+

- HPA (Horizontal Pod Autoscaler) gestioneazÄƒ numÄƒrul de replici:
  minReplicas = 2, maxReplicas = 10
Note:

Monitorul genereazÄƒ logul de sistem periodic.

Backup-ul verificÄƒ modificÄƒrile È™i creeazÄƒ copii cu timestamp.

Nginx expune fiÈ™ierul de log pentru vizualizare externÄƒ.

Autoscalarea se face automat pe baza metricilor CPU È™i memorie.
```

## CI/CD È™i Automatizari
- [Descriere pipeline-uri Jenkins. Puneti aici cat mai detaliat ce face fiecare pipeline de jenkins cu poze facute la pipeline in Blue Ocean. Detaliati cat puteti de mult procesul de CI/CD folosit.]
- [Detalii cu restul cerintelor de CI/CD (cum ati creat userul nou ce are access doar la resursele proiectului, cum ati creat un View now pentru proiect, etc)]
- [Daca ati implementat si punctul E optional atunci detaliati si setupul de minikube.]


## Terraform È™i AWS
- [Prerequiste]
- [InstrucÈ›iuni pentru rularea Terraform È™i configurarea AWS]
- [Daca o sa folositi pentru testare localstack in loc de AWS real puneti aici toti pasii pentru install localstack.]
- [Adaugati instructiunile pentru ca verifica faptul ca Terraform a creat corect infrastructura]

## Depanare si investigarea erorilor
- [Descrieti cum putem accesa logurile aplicatiei si cum ne logam pe fiecare container pentru eventualele depanari de probleme]
- [Descrieti cum ati gandit logurile (formatul logurilor, levelul de log)]


## Resurse
- [Listati aici orice link catre o resursa externa il considerti relevant]
- Exemplu de URL:
- [Sintaxa Markdown](https://www.markdownguide.org/cheat-sheet/)
- [Schelet Proiect](https://github.com/amihai/platforma-monitorizare)
